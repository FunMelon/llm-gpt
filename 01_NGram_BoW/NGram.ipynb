{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:40:44.421662Z",
     "start_time": "2024-11-21T14:40:44.396703Z"
    }
   },
   "source": [
    "# 构建一个玩具数据集\n",
    "corpus = [\n",
    "    \"我喜欢吃苹果\",\n",
    "    \"我喜欢吃香蕉\",\n",
    "    \"她喜欢吃葡萄\",\n",
    "    \"他不喜欢吃香蕉\",\n",
    "    \"他喜欢吃苹果\",\n",
    "    \"她喜欢吃草莓\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T14:43:18.161763Z",
     "start_time": "2024-11-21T14:43:18.156758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义一个分词函数，将文本转化为单个字符的列表\n",
    "def tokenize(text):\n",
    "    return [char for char in text]  # 将文本拆分为字符列表"
   ],
   "id": "4829ebd00731b868",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:26:58.094217Z",
     "start_time": "2024-11-21T15:26:58.071134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义计算N-Gram词频的函数\n",
    "from collections import defaultdict, Counter  # 导入所需的库\n",
    "def count_ngrams(corpus, n):\n",
    "    ngrams_count = defaultdict(Counter)  # 创建一个嵌套词典，存储N-Gram计数\n",
    "    for text in corpus:  # 遍历语料库中的每一个文本\n",
    "        tokens = tokenize(text)  # 对文本进行分词\n",
    "        for i in range(len(tokens) - n + 1):  # 遍历文本中的每一个N-Gram\n",
    "            ngram = tuple(tokens[i:i + n])  # 获取当前N-Gram\n",
    "            prefix = ngram[:-1]  # 获取当前N-Gram的前缀\n",
    "            token = ngram[-1]  # 获取当前N-Gram的目标单字\n",
    "            ngrams_count[prefix][token] += 1  # 更新N-Gram计数\n",
    "    return ngrams_count\n",
    "\n",
    "bigram_counts = count_ngrams(corpus, 2)  # 计算二元语法的词频\n",
    "print(\"Bigram 词频：\")\n",
    "for prefix, counter in bigram_counts.items():\n",
    "    print(prefix, \":\", counter)"
   ],
   "id": "d83dcba91c328e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram 词频：\n",
      "('我',) : Counter({'喜': 2})\n",
      "('喜',) : Counter({'欢': 6})\n",
      "('欢',) : Counter({'吃': 6})\n",
      "('吃',) : Counter({'苹': 2, '香': 2, '葡': 1, '草': 1})\n",
      "('苹',) : Counter({'果': 2})\n",
      "('香',) : Counter({'蕉': 2})\n",
      "('她',) : Counter({'喜': 2})\n",
      "('葡',) : Counter({'萄': 1})\n",
      "('他',) : Counter({'不': 1, '喜': 1})\n",
      "('不',) : Counter({'喜': 1})\n",
      "('草',) : Counter({'莓': 1})\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:51:02.002660Z",
     "start_time": "2024-11-21T15:51:01.981044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义计算N-Gram出现概率的函数\n",
    "def ngram_probabilities(ngram_counts):\n",
    "    ngram_probs = defaultdict(Counter)  # 创建一个嵌套词典，存储N-Gram概率\n",
    "    for prefix, tokens_count in ngram_counts.items(): # 遍历N-Gram前缀\n",
    "        total_count = sum(tokens_count.values())  # 计算当前前缀的总词频\n",
    "        for token, count in tokens_count.items(): # 遍历当前前缀的所有目标单字\n",
    "            ngram_probs[prefix][token] = count / total_count # 计算当前N-Gram的概率\n",
    "    return ngram_probs\n",
    "\n",
    "bigram_probs = ngram_probabilities(bigram_counts)  # 计算二元语法的概率\n",
    "print(\"bigram出现的概率：\")\n",
    "for prefix, probs in bigram_probs.items():\n",
    "    print(\"{}: {}\".format(\"\".join(prefix), dict(probs)))"
   ],
   "id": "b7653333123a3fa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram出现的概率：\n",
      "我: {'喜': 1.0}\n",
      "喜: {'欢': 1.0}\n",
      "欢: {'吃': 1.0}\n",
      "吃: {'苹': 0.3333333333333333, '香': 0.3333333333333333, '葡': 0.16666666666666666, '草': 0.16666666666666666}\n",
      "苹: {'果': 1.0}\n",
      "香: {'蕉': 1.0}\n",
      "她: {'喜': 1.0}\n",
      "葡: {'萄': 1.0}\n",
      "他: {'不': 0.5, '喜': 0.5}\n",
      "不: {'喜': 1.0}\n",
      "草: {'莓': 1.0}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T15:54:24.645713Z",
     "start_time": "2024-11-21T15:54:24.637708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义生成下一个词的函数\n",
    "def generate_next_token(prefix, ngram_probs):\n",
    "    if not prefix in ngram_probs:  # 如果前缀不在N-Gram概率词典中，返回None\n",
    "        return None\n",
    "    next_token_probs = ngram_probs[prefix]  # 获取当前前缀的所有目标单字概率\n",
    "    next_token = max(next_token_probs, key=next_token_probs.get)  # 获取概率最大的目标单字\n",
    "    return next_token"
   ],
   "id": "bf40066b194c374b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:00:07.007450Z",
     "start_time": "2024-11-21T16:00:06.995966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义生成连续文本的函数\n",
    "def generate_text(prefix, ngram_probs, n, length=6):\n",
    "    tokens = list(prefix) # 将前缀转化为列表\n",
    "    for _ in range(length - len(prefix)):\n",
    "        # 获取当前前缀的下一个词\n",
    "        next_token = generate_next_token(tuple(tokens[-n+1:]), ngram_probs)\n",
    "        if not next_token: # 如果下一个词不存在，结束生成\n",
    "            break\n",
    "        tokens.append(next_token)  # 将下一个词添加到文本中\n",
    "    return \"\".join(tokens)  # 将生成的文本转化为字符串"
   ],
   "id": "584857ffab579232",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:01:16.380068Z",
     "start_time": "2024-11-21T16:01:16.368167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成文本\n",
    "generated_text = generate_text(\"她\", bigram_probs, 2)\n",
    "print(\"生成的文本：\", generated_text)"
   ],
   "id": "4e9598e464f1dfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文本： 她喜欢吃苹果\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24a80fd0281e9efb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
